{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "60769d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c79d22",
   "metadata": {},
   "source": [
    "    Environment setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8e38c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self):\n",
    "        self.nS = 16\n",
    "        self.nA = 4 \n",
    "        self.states = [i for i in range(15)]\n",
    "        self.actions = {0:'Left', 1:'Up', 2:'Right', 3:'Down'}\n",
    "        self.env = { \n",
    "            state : {\n",
    "                action : {\n",
    "                    's_Prob':0, 'n_State':0, 's_Reward':0, 'Terminated':False\n",
    "                } for action in [i for i in range(4)]\n",
    "            } for state in [i for i in range(16)]\n",
    "        }\n",
    "        states_set = set(range(16))\n",
    "        action = 0 # action Left\n",
    "        for state in [0, 4, 8, 12]:\n",
    "            self.env[state][0] = {'s_Prob':1, 'n_State':state, 's_Reward':-5, 'Terminated':False}\n",
    "\n",
    "        for state in states_set - set([0, 4, 8, 12]):\n",
    "            self.env[state][0] = {'s_Prob':1, 'n_State':state-1, 's_Reward':-1, 'Terminated':False}\n",
    "\n",
    "\n",
    "        action = 1 # Action Up\n",
    "        for state in [0, 1, 2, 3]:\n",
    "            self.env[state][1] = {'s_Prob':1, 'n_State':state, 's_Reward':-5, 'Terminated':False}\n",
    "\n",
    "        for state in states_set -  set([0, 1, 2, 3]):\n",
    "            self.env[state][1] = {'s_Prob':1, 'n_State':state-4, 's_Reward':-1, 'Terminated':False}\n",
    "\n",
    "\n",
    "        action = 2 # right\n",
    "        for state in [3, 7, 11]:\n",
    "            self.env[state][2] = {'s_Prob':1, 'n_State':state, 's_Reward':-5, 'Terminated':False}\n",
    "\n",
    "        for state in states_set - set([3, 7, 11, 15]):\n",
    "            self.env[state][2] = {'s_Prob':1, 'n_State':state+1, 's_Reward':-1, 'Terminated':False}\n",
    "\n",
    "\n",
    "        action = 3 # action Down \n",
    "        for state in [12, 13, 14]:\n",
    "            self.env[state][3] ={'s_Prob':1, 'n_State':state, 's_Reward':-5, 'Terminated':False}\n",
    "\n",
    "        for state in states_set - set([12, 13, 14, 15]):\n",
    "            self.env[state][3] ={'s_Prob':1, 'n_State':state+4, 's_Reward':-1, 'Terminated':False}\n",
    "\n",
    "\n",
    "\n",
    "        state = 15\n",
    "        self.env[state][0] = {'s_Prob':1, 'n_State':state, 's_Reward':0, 'Terminated':True} # left\n",
    "        self.env[state][1] = {'s_Prob':1, 'n_State':state, 's_Reward':0, 'Terminated':True} # up\n",
    "        self.env[state][2] = {'s_Prob':1, 'n_State':state, 's_Reward':0, 'Terminated':True} # right\n",
    "        self.env[state][3] = {'s_Prob':1, 'n_State':state, 's_Reward':0, 'Terminated':True} # down\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cb7755bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_funtion(prob_matrix, envirnoment):\n",
    "    state_reward = [[env.env[state][action]['s_Reward'] for action in range(4)] for state in range(16)]\n",
    "    # print(state_reward)\n",
    "    reward = state_reward * prob_matrix\n",
    "    # print(reward)\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "77d40212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_funtion(environment, values, reward, prob_matrix, gamma):\n",
    "    values = reward + gamma * (prob_matrix * reward)\n",
    "    return values\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41132ee1",
   "metadata": {},
   "source": [
    "    main funtion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ff966074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    environment = Environment()\n",
    "    print(\"Environment --------\")\n",
    "    print(f'\\nnumber of states : {environment.nS}')\n",
    "    print(f'number of action at each state : {environment.nA}')\n",
    "    print(f'states {environment.states}')\n",
    "    print(f'action {environment.actions.values()}')\n",
    "    print('\\n\\n')\n",
    "    # print(f'env {environment.env}')\n",
    "    prob_matrix_states = [[env.env[state][action]['s_Prob'] for action in range(4)] for state in range(16)]\n",
    "    # print(prob_matrix)\n",
    "    \n",
    "    # random policy in staring \n",
    "    action_prob = numpy.ones((environment.nS, environment.nA)) / environment.nA\n",
    "    print(f\"policy : \\n {action_prob}\")\n",
    "    # prob matrix to reach state {s'} from {s} given action 'a'\n",
    "    prob_matrix = prob_matrix_states * action_prob\n",
    "    # print(prob_matrix)\n",
    "    # print(prob_matrix.shape)\n",
    "    reward = reward_funtion(prob_matrix=prob_matrix, envirnoment=environment)\n",
    "    print(f\"reward : \\n{reward}\")\n",
    "    \n",
    "    values = numpy.zeros((environment.nS, environment.nA))\n",
    "    \n",
    "    values = value_funtion(environment=environment, values=values, reward=reward, prob_matrix=prob_matrix, gamma=1)\n",
    "    \n",
    "    print(f\"values : {values}\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "130d2d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of states : 16\n",
      "number of action at each state : 4\n",
      "states [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "action dict_values(['Left', 'Up', 'Right', 'Down'])\n",
      "policy : \n",
      " [[0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]]\n",
      "reward : \n",
      "[[-1.25 -1.25 -0.25 -0.25]\n",
      " [-0.25 -1.25 -0.25 -0.25]\n",
      " [-0.25 -1.25 -0.25 -0.25]\n",
      " [-0.25 -1.25 -1.25 -0.25]\n",
      " [-1.25 -0.25 -0.25 -0.25]\n",
      " [-0.25 -0.25 -0.25 -0.25]\n",
      " [-0.25 -0.25 -0.25 -0.25]\n",
      " [-0.25 -0.25 -1.25 -0.25]\n",
      " [-1.25 -0.25 -0.25 -0.25]\n",
      " [-0.25 -0.25 -0.25 -0.25]\n",
      " [-0.25 -0.25 -0.25 -0.25]\n",
      " [-0.25 -0.25 -1.25 -0.25]\n",
      " [-1.25 -0.25 -0.25 -1.25]\n",
      " [-0.25 -0.25 -0.25 -1.25]\n",
      " [-0.25 -0.25 -0.25 -1.25]\n",
      " [ 0.    0.    0.    0.  ]]\n",
      "values : [[-1.5625 -1.5625 -0.3125 -0.3125]\n",
      " [-0.3125 -1.5625 -0.3125 -0.3125]\n",
      " [-0.3125 -1.5625 -0.3125 -0.3125]\n",
      " [-0.3125 -1.5625 -1.5625 -0.3125]\n",
      " [-1.5625 -0.3125 -0.3125 -0.3125]\n",
      " [-0.3125 -0.3125 -0.3125 -0.3125]\n",
      " [-0.3125 -0.3125 -0.3125 -0.3125]\n",
      " [-0.3125 -0.3125 -1.5625 -0.3125]\n",
      " [-1.5625 -0.3125 -0.3125 -0.3125]\n",
      " [-0.3125 -0.3125 -0.3125 -0.3125]\n",
      " [-0.3125 -0.3125 -0.3125 -0.3125]\n",
      " [-0.3125 -0.3125 -1.5625 -0.3125]\n",
      " [-1.5625 -0.3125 -0.3125 -1.5625]\n",
      " [-0.3125 -0.3125 -0.3125 -1.5625]\n",
      " [-0.3125 -0.3125 -0.3125 -1.5625]\n",
      " [ 0.      0.      0.      0.    ]]\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c6da3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f1b29f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b86df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d284210a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0167a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a207d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
